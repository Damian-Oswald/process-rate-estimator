---
execute: 
  eval: false
---

# Sensitivity Analysis

Sensitivity analysis is a method used to determine how different values of an independent variable impact a particular dependent variable under a given set of assumptions.

By systematically varying key parameters, sensitivity analysis helps in identifying which variables have the most significant impact on the outcome, aiding in decision-making and risk assessment.

A sensitivity analysis is conducted in five steps:

1. Define parameter distribution.
2. Sample from parameter space.
3. Calculate model output of interest.
4. Approximate the model output based on inputs with an emulator.
5. Use the emulator to calculate parameter contributions to the output variance.

The first step is usually the hardest one, as it requires an extensive review of prior knowledge of the parameters.

## Parameter priors

:::{.column-page}
| End Member             |                                 | Value [‰] | Value reference         | Sampling                         | Range reference   |
|------------------------|---------------------------------|-----------|-------------------------|----------------------------------|-------------------|
| `eta_SP_diffusion`     | $\eta\: \text{SP}_\text{diff.}$ | 1.55      | @well2008isotope        | $\sim \mathcal{N}(1.55, 0.28^2)$ | @well2008isotope  |
| `eta_18O_diffusion`    | $\eta\ce{^{18}O}_\text{diff.}$  | -7.79     | @well2008isotope        | $\sim \mathcal{N}(-7.79, 0.27^2)$| @well2008isotope  |
| `SP_nitrification`     | $\text{SP}_\text{nit.}$         | 34.4      | @decock2013potential    | $\sim \mathcal{U}(26.2, 34.6)$   | @denk2017nitrogen |
| `d18O_nitrification`   | $\delta\ce{^{18}O_\text{nit.}}$ | 36.5      | @lewicka2017quantifying | $\sim \mathcal{N}(36.5, 2^2)$    |                   |
| `SP_denitrification`   | $\text{SP}_\text{den.}$         | -2.4      | @decock2013potential    | $\sim \mathcal{U}(-2.4, -0.9)$   | @denk2017nitrogen |
| `d18O_denitrification` | $\delta\ce{^{18}O_\text{den.}}$ | 11.1      | @lewicka2017quantifying | $\sim \mathcal{N}(11.1, 2^2)$    |                   |
| `eta_SP_reduction`     | $\eta\:\text{SP}_\text{red.}$   | -5.3      | @denk2017nitrogen       | $\sim \mathcal{U}(-8, -2)$       | @denk2017nitrogen |
| `eta_18O_reduction`    | $\eta\ce{^{18}O_\text{red.}}$   | -16.1     | @lewicka2017quantifying | $\sim \mathcal{U}(-24, -6)$      |                   |

: Isotope end members values used for modeling gross nitrification derived N~2~O production, gross denitrification derived N~2~O production, and gross N~2~O reduction. @lewicka2017quantifying originally report $\delta \ce{^{18} O \text - N2O} (\ce{N2O}/\ce{H2O})$. When a range is indicated, a random number from the range was selected in each iteration. When an average and standard deviation is indicated, a random value was drawn from the normal distribution in each iteration. {#tbl-sensitivity tbl-colwidths="[15,10,10,20,15,20]"}
:::

To conduct the sensitivity analysis, a data frame with parameters sampled according to the distributions in @tbl-sensitivity is created. We'll have to specify how many times we want to do this --- in this example that's `n = 200`.

```{r}
n <- 200
parameters <- data.frame(eta_SP_diffusion = rnorm(n, 1.55, 0.28),
                         eta_18O_diffusion = rnorm(n, -7.79, 0.27),
                         SP_nitrification = runif(n, 26.2, 34.6),
                         d18O_nitrification = rnorm(n, 36.5, 2),
                         SP_denitrification = runif(n, -2.4, -0.9),
                         d18O_denitrification = rnorm(n,11.1, 2),
                         eta_SP_reduction = runif(n,-8,-2),
                         eta_18O_reduction = runif(n,-24,-6))
```

Next, we write a function `f` that will run the process rate estimator for a specified column and depth with the parameters in the vector `p` --- which coincides to one row in the `parameters` data frame.

```{r}
f <- function(p, data, column = 1, depth = 7.5) {
    x <- longPRE(data = data,
                 column = column,
                 depth = depth,
                 n = 3,
                 parameters = do.call(getParameters, as.list(p)))
    return(x[["processes"]])
}
```

That function makes it very straightforward to compute the data for the sensitivity analysis. We'll simply apply `f` to every single row in `parameters` using the `apply` function [@wickham2011split].

```{r}
results <- t(apply(parameters, 1, f, data = data, column = 1, depth = 7.5))
```

To conduct the sensitivity analysis, we now model the results based on the sampled parameters -- so we treat the sampled parameters as independent variables $\mathbf X$, and the computed process rates as dependent variables $\mathbf Y$.

A commonly applied method of sensitivity analysis is Sobol's method, which decomposes the total variance and assigns it to individual parameters specific interactions [@sobol1990sensitivity]. However, Sobol's method require's a large number of resampling, and is thus unfit for this application. Instead, a linear regression model is used as an emulator. Often, this works fine enough because even though the reponse might not be linear overall, it can be approximated by a linear model well enough on a specific parameter interval.

First, we might look at the pairwise correlations between columns of $\mathbf X$ and $\mathbf Y$, i.e. all combinations of process rates as well as isotope end members (@fig-sensitivity).

:::{.column-screen-inset}
![Pairwise results of the process rates (y-axis) and the isotope end members (x-axis) for column 1 at 7.5 cm depth. The red lines indicate the respective linear models with their 95% conficence intervals. The black bar to the right of each plot represents the magnitude of the absolute standardized regression coefficient (SRC). The absolute SRC can range from 0 to 1, where an SRC of 1 would range the entire plot plane. As such, these bars represent the importance of a given parameter for emulating the respective process.](graphics/sensitivity.svg){#fig-sensitivity width=100%}
:::

@fig-sensitivity already reveals quite a lot, but it would be better to construct a multiple linear regression model where we include all isotope end members at the same time.

The table below shows the resulting coefficients of such a multiple linear regression model. We can directly interpret the regression coefficients without any further modifications, as all considered variables share the same unit (‰).

:::{.callout-important}
Insert a table with the regression coefficients ($\boldsymbol \beta$) and the standardized regression coefficients ($\boldsymbol \beta^\ast$).
:::

Note that the coefficients of column, depth and their interactions are excluded from this table, even though they are more explanatory than the isotope end members.


## Using a mixed effects model as an emulator

A mixed effects model is a statistical model containing both fixed effects and random effects. In matrix notation, a linear mixed effects model can be represented as follows.
$$
\mathbf y = \mathbf X \boldsymbol \beta + \mathbf Z \boldsymbol \zeta  + \boldsymbol \varepsilon
$${#eq-mem}
In this notation, $\mathbf y$ is a known vector of obervations, where $\mathbb E (\mathbf y) = \mathbf X \boldsymbol \beta$. Unlike in the OLS model, the errors of this mixed effects model are derived from two sources: on one hand from the error vector $\boldsymbol \varepsilon$, but on the other hand also from the random effects $\mathbf Z \boldsymbol \zeta$, where we have both $\mathbb E (\boldsymbol \varepsilon) = \mathbf 0$ and $\mathbb E (\boldsymbol \zeta) = \mathbf 0$. So, generally, the expected error in the model is still zero. However, by use of the term $\mathbf Z \boldsymbol \zeta$, errors might be clustered into groups, where $\mathbf Z$ is a design matrix containing information about these groups.

```{r}
#| echo: false
#| eval: true
#| results: asis
cat(readLines("resources/tbl-sensitivity.txt"))
```

*One interpretation of the fixed effects coefficients $\boldsymbol \beta$ is that they are the estimated population means of the coefficient distributions of the random effects coefficients* [@bates2014fitting].

For approximating the synthetic data within the scope of the sensitivity analysis, we estimate three mixed effects models -- one for Nitrification, Denitrification and Reduction, respectively -- with random intercepts and random slopes. Thus, $3 \cdot 12 \cdot 5 \cdot 2 \cdot 8 + 3 \cdot 2 \cdot 8 = 2928$ parameters are estimated in total.

## How do the process rates correlate?

:::{.column-page}
![Combinations of scatterplots of the estimated process rates for nitrification, denitrification and reduction. Each point represents one mean process rate for a given depth, column and set of randomly drawn parameters according to [table @tbl-sensitivity]. As to be seen, clusters are formed based on combinations of depth and column. The clusters themselves can each be well described as multivariate Gaussians (colored area). The scatterplots are drawn with constrained x- and y-axis limits (**A**) and unconstrained ones (**B**). ](scripts/sensitivity-analysis/output/pairs-processes.svg){#fig-pairs-processes width=100%}
:::

Two things are striking when looking at the clusters in [figure @fig-pairs-processes]: Both the within-group variance as well as the total variance (i.e. the variance of the cluster location) seems to be lower for the deeper depths. Additionally, one of the cluster centers constitutes a massive outlier -- it's column 12 at 7.5 cm depth (@fig-pairs-processes **B**).

## What effect does the bulk density have?

First, we'll determine a range of bulk density to be searched.

```r
BD <- getParameters()$BD + seq(-0.15, 0.15, 0.05)
```

Next, we have to construct a function to return the process estimates for a give bulk density `x`.

```r
f <- function(x) {
    parameters <- getParameters(BD = x)
    data <- subset(measurements, column==1) |>
        getN2ON(parameters = parameters) |>
        getMissing() |>
        calculateFluxes(parameters = parameters)
    return(longPRE(data, 1, 7.5, n = 15)$processes)
}
```

Finally, we'll apply said function to all bulk densities in the vector `BD`.

```r
result <- t(sapply(BD, f))
```

This process will return us the data to be analyzed.

![Illustration to the sensitivity of estimated process rates to a change in prior bulk density.](scripts/sensitivity-analysis/output/bulk-density-sensitiviy.svg){#fig-BD width=100%}

```{r}
#| echo: false
#| eval: true
#| results: asis
data <- read.csv(file.path("scripts","sensitivity-analysis","output","bulk-density-sensitiviy.csv"))
m1 <- lm(Nitrification ~ BD, data)
m2 <- lm(Denitrification ~ BD, data)
m3 <- lm(Reduction ~ BD, data)
#table <- stargazer::stargazer(m1, m2, m3, type = "html")
sjPlot::tab_model(m1, m2, m3, show.p = TRUE, digits = 1, show.ci = FALSE)
```